{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d60741d-d00f-4535-95a4-5f011264e128",
   "metadata": {},
   "source": [
    "# Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e468fd-bead-4b29-ad55-ee945701ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #data science library\n",
    "import seaborn as sns #plotting library\n",
    "sns.set() #sets style of seaborn plots\n",
    "import plotly.express as px #plotting library for fancy interactive plots\n",
    "#!pip install jupyterlab \"ipywidgets>=7.5\"\n",
    "import matplotlib.pyplot as plt #yet another plotting library, python's main one\n",
    "from nltk.corpus import wordnet as wn #A corpus of language from WordNet, a large linguistic resource\n",
    "from nltk.stem.wordnet import WordNetLemmatizer #A Lemmatizer reduces a word to its root form; this imports it.\n",
    "lemmatizer = WordNetLemmatizer() #This 'creates' the lemmatizer\n",
    "from nltk.tokenize import word_tokenize #A Tokenizer breaks text into chunks, usually words\n",
    "from sklearn.preprocessing import MinMaxScaler #This allows us to rescale a column of values to between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb35fa7-0163-4a58-ac9a-cb304018d1f5",
   "metadata": {},
   "source": [
    "# Import the word norm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fcc767-7af2-4ee9-9753-34c12184c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vad = pd.read_excel('vad.xlsx', index_col = 0)  #VAD norms\n",
    "sm = pd.read_excel('sensorimotor.xlsx', index_col = 0) #Sensorimotor norms\n",
    "sm = sm[['auditory', 'gustatory', 'haptic', 'interoceptive', 'olfactory',\n",
    "       'visual', 'foot_leg', 'hand_arm', 'head', 'mouth', 'torso']]\n",
    "\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(sm)\n",
    "\n",
    "# Convert the scaled data back to a DataFrame\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=sm.columns)\n",
    "scaled_df.index = sm.index\n",
    "\n",
    "all_norms = vad.merge(scaled_df, left_index=True, right_index=True) #This creates a dataframe with all \n",
    "                                                                    #our word norm data scaled between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c492a9-9f6e-4f46-9d16-183c26833bc5",
   "metadata": {},
   "source": [
    "# Create a word norm dataframe from raw text that preserves values for each word and one the gives the average of all the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0370d3c0-ab10-4072-8d3e-724fc8f3cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def word_norms(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
    "    \n",
    "    words = []\n",
    "    norms = []\n",
    "    \n",
    "    for i in lemmas:\n",
    "        if i in all_norms.index:\n",
    "            norms.append(sm.loc[i])\n",
    "            words.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    norms_df = pd.DataFrame(norms, index = words)\n",
    "    return norms_df\n",
    "\n",
    "def word_norms_mean(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmas = [lemmatizer.lemmatize(i.lower()) for i in tokens]\n",
    "    \n",
    "    words = []\n",
    "    norms = []\n",
    "    \n",
    "    for i in lemmas:\n",
    "        if i in all_norms.index:\n",
    "            norms.append(sm.loc[i])\n",
    "            words.append(i)\n",
    "        else:\n",
    "            pass\n",
    "    norms_df = pd.DataFrame(norms)\n",
    "    return norms_df.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1566e96-aa7c-4a26-a18b-b94b7b89fdbd",
   "metadata": {},
   "source": [
    "# Example 1: Shakespeare's Sonnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba58e591-2fec-4617-b25d-17dda982ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sonnets.txt\", \"r\") as f:\n",
    "    son = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d8be4a3-88ca-4684-80ca-f834a26961c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sons = son.split(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c341a5aa-87ce-4ff8-b435-fdafba7dd9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean = []\n",
    "\n",
    "for i in sons:\n",
    "    i = i.replace('\\ufeff', '')\n",
    "    i = i.replace('\\n', ' ')\n",
    "    i = i.strip()\n",
    "    clean.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05d1e4-015d-46a1-96e9-393a287fd700",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
